{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from symspellpy.symspellpy import SymSpell, Verbosity\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importación de la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar la tabla completa\n",
    "# combined_reviews = pd.read_sql(\"SELECT * FROM combined_reviews\", con=engine)\n",
    "\n",
    "# # Filtrar en Python\n",
    "# filtered_reviews = combined_reviews.groupby('Modelo estandar').filter(lambda x: x['comentario'].nunique() >= 200)\n",
    "\n",
    "# # Guardar la tabla filtrada nuevamente en MySQL\n",
    "# filtered_reviews.to_sql('filtered_reviews', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_as= pd.read_csv(r\"d:\\Proyecto Web Scrapping\\SQL Queries\\filtered_reviews.csv\")\n",
    "print(df_as.info())  # Resumen del DataFrame\n",
    "print(df_as['calificacion'].value_counts())  # Distribución de calificaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-procesamiento del Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Descargar recursos necesarios de nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Configurar stopwords y lematización\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Función para eliminar la frase completa y Diccionario de correcciones específicas\n",
    "def eliminar_frase(text):\n",
    "    return text.replace(\"(Esta reseña se ha recibido a través de una promoción.)\", \"\")\n",
    "correcciones = {\n",
    "    \"q\": \"que\",\n",
    "    \"exelente\": \"excelente\",\n",
    "    \"espectativas\": \"expectativas\",\n",
    "    \"celu\": \"celular\",\n",
    "    \"bno\": \"bueno\",\n",
    "    \"auriculare\": \"auriculares\",\n",
    "    \"cel\": \"celular\",\n",
    "    \"sultra\": \"ultra\",\n",
    "    \"aprox\": \"aproximadamente\",\n",
    "    \"mobil\": \"movil\",\n",
    "    \"amooo\": \"amo\",\n",
    "    \"perfeccoon\": \"perfeccion\",\n",
    "    \"camras\": \"camaras\",\n",
    "    \"escojer\": \"escoger\",\n",
    "    \"encamta\": \"encanta\",\n",
    "    \"aser\": \"hacer\",\n",
    "    \"calentarce\": \"calentarse\",\n",
    "    \"parese\": \"parece\",\n",
    "    \"nuy\": \"muy\",\n",
    "    \"okey\": \"okay\",\n",
    "    \"espetativas\": \"expectativas\",\n",
    "    \"pq\": \"por que\",\n",
    "    \"mut\": \"muy\",\n",
    "    \"ecxelente\": \"excelente\",\n",
    "    \"execelente\": \"excelente\",\n",
    "    \"bna\": \"buena\",\n",
    "    \"redimiento\": \"rendimiento\",\n",
    "    \"qe\": \"que\",\n",
    "    \"encata\": \"encanta\",\n",
    "    \"sobrecalienta\": \"calienta\",\n",
    "    \"buenardo\": \"bueno\",\n",
    "    \"demaciado\": \"demasiado\",\n",
    "    \"(Esta reseña se ha recibido a través de una promoción.)\": \"\",\n",
    "}\n",
    "# Función para aplicar correcciones específicas\n",
    "def aplicar_correcciones(text):\n",
    "    tokens = text.split()  # Dividir el texto en palabras\n",
    "    corrected_tokens = [correcciones.get(token, token) for token in tokens]  # Reemplazar si hay corrección\n",
    "    return ' '.join(corrected_tokens)  # Volver a unir las palabras\n",
    "\n",
    "\n",
    "# Stopwords personalizadas\n",
    "important_negatives = {\"no\", \"nunca\", \"sin\", \"muy\", \"poco\", \"bastante\", \"mas\", \"dos\", \"mucho\"}\n",
    "stop_words = stop_words - important_negatives\n",
    "\n",
    "# Función para eliminar tildes sin alterar estructura\n",
    "def remove_accents(text):\n",
    "    accents = {\n",
    "        'á': 'a', 'é': 'e', 'í': 'i', 'ó': 'o', 'ú': 'u',\n",
    "        'Á': 'A', 'É': 'E', 'Í': 'I', 'Ó': 'O', 'Ú': 'U'\n",
    "    }\n",
    "    for accented_char, unaccented_char in accents.items():\n",
    "        text = text.replace(accented_char, unaccented_char)  # Reemplazar cada carácter\n",
    "    return text\n",
    "\n",
    "\n",
    "# Función de limpieza completa\n",
    "def clean_text_with_corrections(text):\n",
    "    text = eliminar_frase(text)  # Eliminar la frase específica\n",
    "    text = remove_accents(text)  # Eliminar tildes\n",
    "    text = aplicar_correcciones(text)  # Aplicar correcciones específicas\n",
    "    text = re.sub(r'\\W', ' ', text)  # Eliminar caracteres no alfanuméricos\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Quitar espacios extra\n",
    "    text = re.sub(r'\\d+', '', text)  # Eliminar números\n",
    "    tokens = word_tokenize(text.lower())  # Tokenizar\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]  # Lematización y filtro\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Rellenar valores NaN en la columna 'comentario' con una cadena vacía\n",
    "df_as['comentario'] = df_as['comentario'].fillna('')\n",
    "\n",
    "# Aplicar al DataFrame\n",
    "df_as['comentario_limpio'] = df_as['comentario'].apply(clean_text_with_corrections)\n",
    "\n",
    "# Verificar cambios\n",
    "print(\"Primeros comentarios limpios en el DataFrame de prueba:\")\n",
    "print(df_as[['comentario', 'comentario_limpio']].head(10))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
